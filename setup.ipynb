{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c9c860",
   "metadata": {},
   "source": [
    "# Set up\n",
    "### Goal\n",
    "\n",
    "1. Build a predictive model with XGBoost\n",
    "2. Deploy that model to Triton Inference Server\n",
    "3. Make predictions\n",
    "\n",
    "### Architecture\n",
    "\n",
    "* Host: GPU (P40 or V100) and CUDA running on Ubuntu 20.4 with plenty of disk space\n",
    "* Triton Container from NGC (open ports 8000, 8001, 8002)\n",
    "* PyTorch Container from NGC (open port 8888)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83552f2d",
   "metadata": {},
   "source": [
    "## Set up Host\n",
    "\n",
    "See host document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cafb9d",
   "metadata": {},
   "source": [
    "## Set up Docker network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker network create tritonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a3b03",
   "metadata": {},
   "source": [
    "## Pull docker containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54826e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triton\n",
    "sudo docker pull nvcr.io/nvidia/tritonserver:22.03-py3\n",
    "sudo docker run --gpus=all -d -p 8000:8000 -p 8001:8001 -p 8002:8002 --network=tritonnet -v /home/azureuser/model_repository:/models \\\n",
    "    --name tritonserver nvcr.io/nvidia/tritonserver:22.03-py3 tritonserver --model-repository=/models\n",
    "\n",
    "# PyTorch\n",
    "sudo docker volume create volume1\n",
    "sudo docker pull nvcr.io/nvidia/pytorch:22.03-py3\n",
    "sudo docker run --gpus=all -t -d -p 8888:8888 --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 --network=tritonnet \\\n",
    "    --mount source=volume1,destination=/workspace/triton --name pytorch nvcr.io/nvidia/pytorch:22.03-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be8693",
   "metadata": {},
   "source": [
    "## Start Jupyter Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker exec -it pytorch /bin/bash\n",
    "nohup jupyter-lab --NotebookApp.token='' --no-browser --port=8888 &\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242a4c6",
   "metadata": {},
   "source": [
    "## Identify Triton IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ded950",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker network inspect tritonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a164365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
