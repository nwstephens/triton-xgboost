{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c9c860",
   "metadata": {},
   "source": [
    "# Set up PyTorch and Triton Containers\n",
    "\n",
    "This step will download and run two docker containers from NGC. We will use the PyTorch container to build a predictive model using XGBoost. Then we will deploy that model to the Triton container. The two containers are networked so that requests from the PyTorch container can be submitted to the Triton server.\n",
    "\n",
    "### Set up notes\n",
    "\n",
    "* Make sure you have properly set up your server as described in [Configuring the server]().\n",
    "* You should have plenty of disk space (at least 64 GB)\n",
    "* Open parts 8000, 8001, 8002 for Triton\n",
    "* Open port 8888 for Jupyter Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cafb9d",
   "metadata": {},
   "source": [
    "## Set up docker network\n",
    "\n",
    "Create a docker network for the containers to communicate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker network create tritonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a3b03",
   "metadata": {},
   "source": [
    "## Pull and run docker containers\n",
    "\n",
    "Pull the contains are run them within the network. Mount a volume on the PyTorch container. This volume will be used to save models that will later be transfered to the Triton model repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54826e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triton\n",
    "sudo docker pull nvcr.io/nvidia/tritonserver:22.03-py3\n",
    "sudo docker run --gpus=all -d -p 8000:8000 -p 8001:8001 -p 8002:8002 --network=tritonnet -v /home/azureuser/model_repository:/models \\\n",
    "    --name tritonserver nvcr.io/nvidia/tritonserver:22.03-py3 tritonserver --model-repository=/models\n",
    "\n",
    "# PyTorch\n",
    "sudo docker volume create volume1\n",
    "sudo docker pull nvcr.io/nvidia/pytorch:22.03-py3\n",
    "sudo docker run --gpus=all -t -d -p 8888:8888 --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 --network=tritonnet \\\n",
    "    --mount source=volume1,destination=/workspace/triton --name pytorch nvcr.io/nvidia/pytorch:22.03-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be8693",
   "metadata": {},
   "source": [
    "## Start Jupyter Lab\n",
    "\n",
    "Jupyter Lab is preinstalled on the PyTorch container. You can run it in headless mode on port 8888. Note that the code below removes the token. If you want to use a security token when you log into the server, you can remove the comment `NotebeookApp.token=''`. Once Jupyter Lab is running, you can access it at `http://<server-ip>:8888/lab?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker exec -it pytorch /bin/bash\n",
    "nohup jupyter-lab --NotebookApp.token='' --no-browser --port=8888 &\n",
    "exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242a4c6",
   "metadata": {},
   "source": [
    "## Identify Triton IP\n",
    "\n",
    "Make a note of the IP of the Triton server for the later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ded950",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker network inspect tritonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16234a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker logs tritonserver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
